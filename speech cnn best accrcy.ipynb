{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      file_name  fold  caseno                         label\n",
      "0        a1.wav     2       5                        Normal\n",
      "1        6a.wav     2       6                        Normal\n",
      "2    12(S1).wav     2      12                        Normal\n",
      "3     12(A).wav     2      12                        Normal\n",
      "4     12(S).wav     2      12                        Normal\n",
      "5    12(S1).wav     2      12                        Normal\n",
      "6     22(A).wav     2      22                        Normal\n",
      "7    22(A1).wav     2      22                        Normal\n",
      "8    22(S1).wav     2      22                        Normal\n",
      "9    22(S1).wav     2      22                        Normal\n",
      "10    22(W).wav     2      22                        Normal\n",
      "11    29(A).wav     2      29                        Normal\n",
      "12   29(A1).wav     2      29                        Normal\n",
      "13    29(V).wav     2      29                        Normal\n",
      "14    29(A).wav     2      29                        Normal\n",
      "15    29(S).wav     2      29                        Normal\n",
      "16    30(S).wav     2      30                        Normal\n",
      "17    31(S).wav     2      31                        Normal\n",
      "18    34(S).wav     2      34                        Normal\n",
      "19    34(W).wav     2      34                        Normal\n",
      "20   08(A1).wav     3       8         Phonological Disorder\n",
      "21    8(S1).wav     3       8         Phonological Disorder\n",
      "22     8(A).wav     3       8         Phonological Disorder\n",
      "23     8(S).wav     3       8         Phonological Disorder\n",
      "24    8(S1).wav     3       8         Phonological Disorder\n",
      "25     8(V).wav     3       8         Phonological Disorder\n",
      "26    8(S1).wav     3       8         Phonological Disorder\n",
      "27    17(A).wav     3      17         Phonological Disorder\n",
      "28   17(A1).wav     3      17         Phonological Disorder\n",
      "29    17(S).wav     3      17         Phonological Disorder\n",
      "..          ...   ...     ...                           ...\n",
      "41    1(ST).wav     4       1  Speech and language disorder\n",
      "42    1(ST).wav     4       1  Speech and language disorder\n",
      "43     1(T).wav     4       1  Speech and language disorder\n",
      "44  1(Tbls).wav     4       1  Speech and language disorder\n",
      "45     1(V).wav     4       1  Speech and language disorder\n",
      "46  002(S1).wav     4       2  Speech and language disorder\n",
      "47  002(S1).wav     4       2  Speech and language disorder\n",
      "48    02(S).wav     4       2  Speech and language disorder\n",
      "49   02(S1).wav     4       2  Speech and language disorder\n",
      "50     2(A).wav     4       2  Speech and language disorder\n",
      "51     2(A).wav     4       2  Speech and language disorder\n",
      "52    2(A1).wav     4       2  Speech and language disorder\n",
      "53     2(S).wav     4       2  Speech and language disorder\n",
      "54    2(S1).wav     4       2  Speech and language disorder\n",
      "55     2(V).wav     4       2  Speech and language disorder\n",
      "56     9(A).wav     4       9  Speech and language disorder\n",
      "57    9(A1).wav     4       9  Speech and language disorder\n",
      "58    15(A).wav     4      15  Speech and language disorder\n",
      "59    18(A).wav     4      18  Speech and language disorder\n",
      "60    18(A).wav     4      18  Speech and language disorder\n",
      "61   18(A1).wav     4      18  Speech and language disorder\n",
      "62    18(A).wav     4      18  Speech and language disorder\n",
      "63    25(A).wav     4      25  Speech and language disorder\n",
      "64    25(S).wav     4      25  Speech and language disorder\n",
      "65   25(S1).wav     4      25  Speech and language disorder\n",
      "66    25(V).wav     4      25  Speech and language disorder\n",
      "67   25(A1).wav     4      25  Speech and language disorder\n",
      "68    27(A).wav     4      27  Speech and language disorder\n",
      "69    27(A).wav     4      27  Speech and language disorder\n",
      "70   27(A1).wav     4      27  Speech and language disorder\n",
      "\n",
      "[71 rows x 4 columns]\n",
      "Finished feature extraction from  71 files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_pad_len = 7223\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        #print(sample_rate)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        #print(mfccs.shape)\n",
    "        \n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs\n",
    "\n",
    "# Load various imports \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = 'E:/ME SATHIYA/orginaldata/audio/'\n",
    "metadata = pd.read_csv('E:/ME SATHIYA/orginaldata/metadata/orginaldata.csv')\n",
    "print(metadata)\n",
    "\n",
    "features = []\n",
    "\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'\\\\'+'caseno'+str(row[\"caseno\"])+'\\\\'+str(row[\"file_name\"]))\n",
    "    \n",
    "    class_label = row[\"label\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 40, 7223)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 40, 7223, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 7223\n",
    "num_channels = 1\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "print(x_test.shape)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 7222, 16)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 3611, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 3611, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 3610, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 1805, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 1805, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 1804, 64)       8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 902, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 902, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 901, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 450, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 450, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 43,699\n",
      "Trainable params: 43,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 46.6667%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.2962 - accuracy: 0.8571 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.4070 - accuracy: 0.8214 - val_loss: 1.3884 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.5621 - accuracy: 0.8036 - val_loss: 1.4813 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.4433 - accuracy: 0.8214 - val_loss: 0.3532 - val_accuracy: 0.8667\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.4799 - accuracy: 0.8036 - val_loss: 0.2180 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.5257 - accuracy: 0.7143 - val_loss: 0.4306 - val_accuracy: 0.7333\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.3274 - accuracy: 0.8571 - val_loss: 0.3932 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.2890 - accuracy: 0.8750 - val_loss: 0.7568 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.3622 - accuracy: 0.8393 - val_loss: 0.2078 - val_accuracy: 0.9333\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.3605 - accuracy: 0.8036 - val_loss: 0.3117 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.4571 - accuracy: 0.7143 - val_loss: 0.1935 - val_accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.3194 - accuracy: 0.8571 - val_loss: 0.6626 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.3507 - accuracy: 0.8750 - val_loss: 1.1814 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.3132 - accuracy: 0.8750 - val_loss: 0.8859 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.3371 - accuracy: 0.8571 - val_loss: 0.2279 - val_accuracy: 0.9333\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.3031 - accuracy: 0.8750 - val_loss: 0.2322 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.3645 - accuracy: 0.8393 - val_loss: 0.1911 - val_accuracy: 0.9333\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.2602 - accuracy: 0.9107 - val_loss: 0.7406 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.3634 - accuracy: 0.8393 - val_loss: 0.6023 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.2510 - accuracy: 0.8750 - val_loss: 0.3550 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.2903 - accuracy: 0.8929 - val_loss: 0.3027 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.3439 - accuracy: 0.8393 - val_loss: 0.4135 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.2903 - accuracy: 0.8393 - val_loss: 0.6656 - val_accuracy: 0.7333\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.2858 - accuracy: 0.8750 - val_loss: 0.2866 - val_accuracy: 0.9333\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 0.2571 - accuracy: 0.8750 - val_loss: 0.1868 - val_accuracy: 0.9333\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 9s 158ms/step - loss: 0.2613 - accuracy: 0.8929 - val_loss: 0.1847 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.2466 - accuracy: 0.9286 - val_loss: 0.1917 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.2592 - accuracy: 0.8929 - val_loss: 0.2318 - val_accuracy: 0.9333\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.2387 - accuracy: 0.8571 - val_loss: 0.1897 - val_accuracy: 0.9333\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.2220 - accuracy: 0.9107 - val_loss: 0.1844 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.2476 - accuracy: 0.9107 - val_loss: 0.1902 - val_accuracy: 0.9333\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.2263 - accuracy: 0.8929 - val_loss: 0.2893 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.2386 - accuracy: 0.8929 - val_loss: 0.2707 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.2385 - accuracy: 0.8929 - val_loss: 0.1830 - val_accuracy: 0.9333\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.2124 - accuracy: 0.8750 - val_loss: 0.1715 - val_accuracy: 0.9333\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.2305 - accuracy: 0.9286 - val_loss: 0.1679 - val_accuracy: 0.9333\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.2129 - accuracy: 0.9286 - val_loss: 0.1751 - val_accuracy: 0.9333\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.2133 - accuracy: 0.8929 - val_loss: 0.2313 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.2347 - accuracy: 0.8929 - val_loss: 0.1963 - val_accuracy: 0.9333\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.2079 - accuracy: 0.9286 - val_loss: 0.1660 - val_accuracy: 0.9333\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.2189 - accuracy: 0.9286 - val_loss: 0.1684 - val_accuracy: 0.9333\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.2029 - accuracy: 0.9286 - val_loss: 0.1693 - val_accuracy: 0.9333\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.2066 - accuracy: 0.8929 - val_loss: 0.2099 - val_accuracy: 0.9333\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.2212 - accuracy: 0.9107 - val_loss: 0.1788 - val_accuracy: 0.9333\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.2085 - accuracy: 0.9286 - val_loss: 0.1651 - val_accuracy: 0.9333\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.1962 - accuracy: 0.9286 - val_loss: 0.1649 - val_accuracy: 0.9333\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.2030 - accuracy: 0.9107 - val_loss: 0.1696 - val_accuracy: 0.9333\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.2090 - accuracy: 0.9107 - val_loss: 0.1901 - val_accuracy: 0.9333\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.2083 - accuracy: 0.9107 - val_loss: 0.1899 - val_accuracy: 0.9333\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.1963 - accuracy: 0.9107 - val_loss: 0.1653 - val_accuracy: 0.9333\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.1980 - accuracy: 0.9107 - val_loss: 0.1652 - val_accuracy: 0.9333\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.1868 - accuracy: 0.9107 - val_loss: 0.1685 - val_accuracy: 0.9333\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.1835 - accuracy: 0.9107 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.2036 - accuracy: 0.9286 - val_loss: 0.1711 - val_accuracy: 0.9333\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.1881 - accuracy: 0.8929 - val_loss: 0.1668 - val_accuracy: 0.9333\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.2093 - accuracy: 0.9107 - val_loss: 0.1786 - val_accuracy: 0.9333\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 8s 145ms/step - loss: 0.1828 - accuracy: 0.9107 - val_loss: 0.4121 - val_accuracy: 0.7333\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.2063 - accuracy: 0.8750 - val_loss: 0.1799 - val_accuracy: 0.9333\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.2086 - accuracy: 0.8929 - val_loss: 0.1648 - val_accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.1713 - accuracy: 0.9107 - val_loss: 0.1804 - val_accuracy: 0.9333\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.1888 - accuracy: 0.9107 - val_loss: 0.1970 - val_accuracy: 0.9333\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.1911 - accuracy: 0.9107 - val_loss: 0.1646 - val_accuracy: 0.9333\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 8s 148ms/step - loss: 0.2121 - accuracy: 0.8929 - val_loss: 0.1639 - val_accuracy: 0.9333\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1753 - accuracy: 0.9286 - val_loss: 0.2165 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1894 - accuracy: 0.9107 - val_loss: 0.1692 - val_accuracy: 0.9333\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.1633 - accuracy: 0.9821 - val_loss: 0.1718 - val_accuracy: 0.9333\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1742 - accuracy: 0.9643 - val_loss: 0.1627 - val_accuracy: 0.9333\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.1826 - accuracy: 0.9107 - val_loss: 0.2367 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1856 - accuracy: 0.9107 - val_loss: 0.1913 - val_accuracy: 0.9333\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1935 - accuracy: 0.9107 - val_loss: 0.1733 - val_accuracy: 0.9333\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.1733 - accuracy: 0.9643 - val_loss: 0.1645 - val_accuracy: 0.9333\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.1822 - accuracy: 0.9107 - val_loss: 0.1945 - val_accuracy: 0.9333\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 9s 152ms/step - loss: 0.1626 - accuracy: 0.9464 - val_loss: 0.1807 - val_accuracy: 0.9333\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1866 - accuracy: 0.8750 - val_loss: 0.1642 - val_accuracy: 0.9333\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.1761 - accuracy: 0.9464 - val_loss: 0.1640 - val_accuracy: 0.9333\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.1584 - accuracy: 0.9286 - val_loss: 0.1680 - val_accuracy: 0.9333\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.1564 - accuracy: 0.9286 - val_loss: 0.1780 - val_accuracy: 0.9333\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.1552 - accuracy: 0.9286 - val_loss: 0.1676 - val_accuracy: 0.9333\n",
      "Epoch 79/100\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.1386 - accuracy: 0.9464 - val_loss: 0.1691 - val_accuracy: 0.9333\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1661 - accuracy: 0.8929 - val_loss: 0.1705 - val_accuracy: 0.9333\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.1529 - accuracy: 0.9286 - val_loss: 0.1701 - val_accuracy: 0.9333\n",
      "Epoch 82/100\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.1494 - accuracy: 0.9286 - val_loss: 0.1724 - val_accuracy: 0.9333\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.1551 - accuracy: 0.9107 - val_loss: 0.1717 - val_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.1649 - accuracy: 0.9464 - val_loss: 0.1756 - val_accuracy: 0.9333\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.1628 - accuracy: 0.9286 - val_loss: 0.2088 - val_accuracy: 0.8667\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 9s 166ms/step - loss: 0.1403 - accuracy: 0.9464 - val_loss: 0.1763 - val_accuracy: 0.9333\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.1423 - accuracy: 0.9464 - val_loss: 0.1860 - val_accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.1813 - accuracy: 0.9107 - val_loss: 0.2185 - val_accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 9s 165ms/step - loss: 0.1568 - accuracy: 0.9107 - val_loss: 0.1796 - val_accuracy: 0.9333\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.1426 - accuracy: 0.9643 - val_loss: 0.1773 - val_accuracy: 0.9333\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 9s 158ms/step - loss: 0.1408 - accuracy: 0.9464 - val_loss: 0.1807 - val_accuracy: 0.9333\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.1429 - accuracy: 0.9643 - val_loss: 0.2066 - val_accuracy: 0.9333\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.1722 - accuracy: 0.9107 - val_loss: 0.1803 - val_accuracy: 0.9333\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.1468 - accuracy: 0.9286 - val_loss: 0.1844 - val_accuracy: 0.9333\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.1516 - accuracy: 0.9464 - val_loss: 0.1784 - val_accuracy: 0.9333\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.1257 - accuracy: 0.9643 - val_loss: 0.2137 - val_accuracy: 0.8667\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.1609 - accuracy: 0.9464 - val_loss: 0.1884 - val_accuracy: 0.9333\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 0.1794 - accuracy: 0.9286 - val_loss: 0.1951 - val_accuracy: 0.9333\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.1920 - accuracy: 0.9286 - val_loss: 0.6369 - val_accuracy: 0.8000\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.1976 - accuracy: 0.9286 - val_loss: 0.2038 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1adb7d7a518>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
